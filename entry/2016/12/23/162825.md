
+++
date = "2016-12-23 16:28:25 +0000 UTC"
draft = false
title = "ElasticsearchのScroll  APIをためしてみた"
tags = ["elasticsearch","kotlin","Scroll"]

+++
気になっていたElasticsearchのScroll APIの使用感を記録します。最近の開発でScroll APIを採用したい欲求がありましたが、使用感を調べる前で採用は見送りました。このままだと気になったまま使わないことになりそうなので、この機会にまとめます。[Scroll | Elasticsearch Reference [2.4] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/2.4/search-request-scroll.html)※ version 2.4をつかいました。Scroll APIは通常のSearch requestのoffset/limitでページング取得をしないため処理中のデータ抜けが防げるメリットがあります。またScroll APIは初回リクエスト時の結果をスナップショットすることで安定した応答速度を担保します。<br/>
スナップショットをとるためリアルタイムのデータ処理の利用には向いていません。（スナップショットの挙動について試してみたので後述しています）

<div class="section">
    ### どんなふうに使うか？
    通常のクエリと**scroll=1m**を加えたリクエストを送ります。（size=1にしています）
```sh
curl -XGET &#39;http://localhost:9200/_search?scroll=1m&amp;size=1&amp;pretty&#39; -d &#39;
{
"query" : { "match" : { "category_id" : 100 } }
}&#39;

```次のような検索結果（1件）と合わせて**_scroll_id**が返ってきます。
```sh
{
  "_scroll_id" : "cXVlcnlUaGVuRmV0Y2g7NTs4OkZRQjk1VGJIUmxhRm5RVlBnVWotYXc7OTpGUUI5NVRiSFJsYUZuUVZQZ1VqLWF3OzEwOkZRQjk1VGJIUmxhRm5RVlBnVWotYXc7MTE6RlFCOTVUYkhSbGFGblFWUGdVai1hdzsxMjpGUUI5NVRiSFJsYUZuUVZQZ1VqLWF3OzA7",
・・・
  "hits" : {
    "total" : 52,
・・・
  }
}

```２件目の取得を行うために**/_search/scroll**のエンドポイントへ**scroll_id**をRequest Bodyに加えてリクエストします。クエリは必要ありません。
```sh
curl -XGET &#39;http://localhost:9200/_search/scroll?pretty&#39; -d &#39;
{
"scroll_id": "cXVlcnlUaGVuRmV0Y2g7NTs4OkZRQjk1VGJIUmxhRm5RVlBnVWotYXc7OTpGUUI5NVRiSFJsYUZuUVZQZ1VqLWF3OzEwOkZRQjk1VGJIUmxhRm5RVlBnVWotYXc7MTE6RlFCOTVUYkhSbGFGblFWUGdVai1hdzsxMjpGUUI5NVRiSFJsYUZuUVZQZ1VqLWF3OzA7"
}&#39;

```
<ul>
<li>２回目以降はscroll_idを送ることで初回のリクエスト時に送った検索条件の結果が返ってきます。</li>
<li>３回目以降も同様にscroll_idを送ることで３件目、４件目、５件目・・・と結果を取得できます。</li>
<li>初回に**size=1**としたため、２回目以降の結果も１件になります。</li>
<li>また**scroll=1m**としたことで初回にリクエストした検索条件の結果を1分間の有効期限でスナップショットが取られます。</li>
</ul>
</div>
<div class="section">
    ### 使い終わったscroll_idは破棄をする
    スナップショットを残して置くのはコストがかかるためscrollが終われば次のようにscroll_idをクリアします。
```sh
curl -XDELETE localhost:9200/_search/scroll -d &#39;
{
    "scroll_id" : ["cXVlcnlUaGVuRmV0Y2g7NTs4OkZRQjk1VGJIUmxhRm5RVlBnVWotYXc7OTpGUUI5NVRiSFJsYUZuUVZQZ1VqLWF3OzEwOkZRQjk1VGJIUmxhRm5RVlBnVWotYXc7MTE6RlFCOTVUYkhSbGFGblFWUGdVai1hdzsxMjpGUUI5NVRiSFJsYUZuUVZQZ1VqLWF3OzA7"]
}&#39;

```複数のscroll_idをまとめてクリアもできます。

</div>
<div class="section">
    ### Scroll APIを使うときのメモ
    
<ul>
<li>Scroll APIの初回のリクエストはscroll_idを取得するためのものではなく、検索結果に加えてscroll_idが返ってくる。</li>
<li>Aggregationを含んだリクエストの場合、Aggregationの結果は初回のみ返ってくる。</li>
<li>ソート条件に制約がなければsort orderは**_doc**にすることで安定した応答速度が得られる。</li>
</ul>
</div>
<div class="section">
    ### kotlin + 公式Elasticsearch ClientでScroll APIをためしてみる
    せっかくなのでkotlinでコードからScroll APIをためしてみました。使ったクライアントは公式のElasticsearch Clientです。[Client | Java API [2.4] | Elastic](https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.4/client.html)※ version 2.4.3をつかいました

<div class="section">
    #### スナップショットは本当に有効なのか？
    **scroll=1m**と設定してインデックスされたデータをscroll取得している間に、新しいソースをインデックスしても取得結果のtotal件数に変化がないか試してみました。以下のような流れで検証します。<script src="https://gist.github.com/f1ffde4a9665dc6aa74f5498938f7544.js"> </script>scrollIdが取得できれば再帰的にログ出力を繰り返し、その間に新しいソースを１件追加していきます。実行した結果は次のようになりました。
```sh
[INFO ] totalCount={104}, id={AVkna34Rhpv5RJ12skTc}　　　// 初回取得時のtotal件数は104件
[INFO ] complete add source id={AVkqcnqbMJXjH5tvLcGB}　　//新しいソースの追加が成功
[INFO ] totalCount={104}, id={AVkna_83hpv5RJ12skTd}　　　// total件数は初回取得時の104件から変わらずスナップショットが有効であることが確認できた
[INFO ] complete add source id={AVkqcntGMJXjH5tvLcGC}
[INFO ] totalCount={104}, id={AVknbG17hpv5RJ12skTf}
・・・

```Scroll APIの仕様のとおりスナップショットが有効の状態であれば新しいソースを追加したとしてもスナップショットを指すscroll_idでリクエストをすると全体の件数は変わらないことが確認できました。

</div>
</div>
<div class="section">
    ### まとめ
    
<ul>
<li>ページング処理ではないため取りこぼしがない。（そもそも初回時点のスナップショットのデータを対象にスクロールするので取りこぼしはないと思われる）</li>
<li>offset/limitのページング処理のコードがなくなり、コードがシンプルになった。</li>
<li>スナップショットの有効期限が切れた場合、**SearchContextMissingException**がスローされる。</li>
<li>SearchContextMissingExceptionを捕捉して新規スクロールを始める必要があるが、例外が起きた時点のソースIDを始点にスクロールを開始する・・・なかなか例外処理は複雑。</li>
<li>取得したscroll_idを用いた次のスクロールに有効期限を添えることで常にスナップショットの有効期限を更新すれば例外処理を避けることができそう。</li>
<li>いまのプロジェクトに導入したくなってきたが、本番での処理時間を測定した上で最適な有効期限の設定をする必要があるため様子見する。</li>
</ul>
</div>
<div class="section">
    ### ソースを公開しています
    今回検証したソースコードを公開しています。
<div class="github-card" data-user="nsoushi" data-repo="elasticsearch_test" data-width="400" data-height="" data-theme="default"></div>
<script src="https://cdn.jsdelivr.net/github-cards/latest/widget.js"></script>
<br/>


</div>
<div class="section">
    ### 関連エントリ
    [Logstash + Elasticsearch連携時のLogstash confメモ（jsonからconvert, filter, dateなど） - 平日インプット週末アウトプットぶろぐ](http://naruto-io.hatenablog.com/entry/2016/11/08/160204)<br/>
[fluentd + logstash_formatの難点をrecord_reformerで解決した話 - 平日インプット週末アウトプットぶろぐ](http://naruto-io.hatenablog.com/entry/2016/12/10/170633)

</div>

